{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd8199da5da04fae81bab3a544c21c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c81c81f79b0474185694de3da579878",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1561a13f9f19455c84034ed9d5bf1d51",
              "IPY_MODEL_a67ad09ab62b4a548eb7f3d2944c266f"
            ]
          }
        },
        "8c81c81f79b0474185694de3da579878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1561a13f9f19455c84034ed9d5bf1d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e8fe17f0f954224b8cbbc5e925138e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21ba8e47d7bb4ba38a569ca1ac6d4393"
          }
        },
        "a67ad09ab62b4a548eb7f3d2944c266f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d68d4e68a4444bf4a299db2bb804c0c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:11&lt;00:00, 38.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51ea411211e04a75a4b9533af865e3df"
          }
        },
        "3e8fe17f0f954224b8cbbc5e925138e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21ba8e47d7bb4ba38a569ca1ac6d4393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d68d4e68a4444bf4a299db2bb804c0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51ea411211e04a75a4b9533af865e3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c201b554a884417da6ff13ea2ad871f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f37c03030c1458ebeb42ef12b7e1922",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c79b6d7b109046a09fcbe005d1a14788",
              "IPY_MODEL_6f442eb07a8b4a48809075ae72670e8f"
            ]
          }
        },
        "2f37c03030c1458ebeb42ef12b7e1922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c79b6d7b109046a09fcbe005d1a14788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f24c9ab1b3f46588fd4b89d48874f9a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12aa1f4f5c4841f0964852593d4c4ea5"
          }
        },
        "6f442eb07a8b4a48809075ae72670e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f10a00a35c2743a299a766b077460d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:10&lt;00:00, 49.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c354fdf6a73945e5bcf3d132c3977873"
          }
        },
        "4f24c9ab1b3f46588fd4b89d48874f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12aa1f4f5c4841f0964852593d4c4ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f10a00a35c2743a299a766b077460d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c354fdf6a73945e5bcf3d132c3977873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caseyhyoon/W266-Final-Project/blob/casey/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsZarCZoPybd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bmc-wxyQdIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89878132-de41-46c4-87e5-c6a5d9f322d8"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDmHLFq-Pybi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd67118-8737-4d29-d10a-3be5c1c51b09"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'twitter_sexism_parsed_dataset.csv',\n",
              " 'twitter_racism_parsed_dataset.csv',\n",
              " 'twitter_parsed_dataset.csv',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1vgKcEPybj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "31782087-ab13-413f-9db3-329a8c4581e1"
      },
      "source": [
        "parsed = pd.read_csv('twitter_parsed_dataset.csv')\n",
        "racism = pd.read_csv('twitter_racism_parsed_dataset.csv')\n",
        "sexism = pd.read_csv('twitter_sexism_parsed_dataset.csv')\n",
        "\n",
        "twitter_data = pd.concat([parsed, racism, sexism]).dropna()\n",
        "twitter_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>oh_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.74948705591165E+017</td>\n",
              "      <td>5.74948705591165E+017</td>\n",
              "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.71917888690393E+017</td>\n",
              "      <td>5.71917888690393E+017</td>\n",
              "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.90255841338601E+017</td>\n",
              "      <td>3.90255841338601E+017</td>\n",
              "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.68208850655916E+017</td>\n",
              "      <td>5.68208850655916E+017</td>\n",
              "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
              "      <td>racism</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.75596338802373E+017</td>\n",
              "      <td>5.75596338802373E+017</td>\n",
              "      <td>#mkr No No No No No No</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   index                     id  ... Annotation oh_label\n",
              "0  5.74948705591165E+017  5.74948705591165E+017  ...       none      0.0\n",
              "1  5.71917888690393E+017  5.71917888690393E+017  ...       none      0.0\n",
              "2  3.90255841338601E+017  3.90255841338601E+017  ...     sexism      1.0\n",
              "3  5.68208850655916E+017  5.68208850655916E+017  ...     racism      1.0\n",
              "4  5.75596338802373E+017  5.75596338802373E+017  ...       none      0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NXJ1CETkPybk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "427ba9e9-e47f-487c-e007-b018c7b9842b"
      },
      "source": [
        "### Cleaning tweets\n",
        "\n",
        "def cleaning_tweets(tweet):\n",
        "    # 1. Remove Twitter handles (@user)\n",
        "    users = re.findall(\"@[\\w]*\", tweet) # tokenizing\n",
        "    for user in users:\n",
        "        tweet = re.sub(user, '', tweet)\n",
        "        \n",
        "    # 2. Remove urls\n",
        "    tweet = re.sub(r'http\\S+', '', tweet)\n",
        "\n",
        "    # 3. Remove, Punctuations, Numbers, and Special Characters (keep hashtags)\n",
        "    tweet = tweet.replace(\".\", \" \").replace(\",\", \" \").replace(\"?\", \" \").replace(\"!\", \" \")\n",
        "    tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
        "    tweet = re.sub('[0-9]+', '', tweet)\n",
        "\n",
        "    # 4. Lowercase all\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    return tweet\n",
        "\n",
        "twitter_data['cleaned_tweets'] = twitter_data['Text'].apply(cleaning_tweets)\n",
        "twitter_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>oh_label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.74948705591165E+017</td>\n",
              "      <td>5.74948705591165E+017</td>\n",
              "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i read them in context no change in meaning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.71917888690393E+017</td>\n",
              "      <td>5.71917888690393E+017</td>\n",
              "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "      <td>now you idiots claim that people who tried to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.90255841338601E+017</td>\n",
              "      <td>3.90255841338601E+017</td>\n",
              "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>1.0</td>\n",
              "      <td>rt  call me sexist  but when i go to an auto p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.68208850655916E+017</td>\n",
              "      <td>5.68208850655916E+017</td>\n",
              "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
              "      <td>racism</td>\n",
              "      <td>1.0</td>\n",
              "      <td>wrong  isis follows the example of mohammed a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.75596338802373E+017</td>\n",
              "      <td>5.75596338802373E+017</td>\n",
              "      <td>#mkr No No No No No No</td>\n",
              "      <td>none</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mkr no no no no no no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   index  ...                                     cleaned_tweets\n",
              "0  5.74948705591165E+017  ...     i read them in context no change in meaning...\n",
              "1  5.71917888690393E+017  ...   now you idiots claim that people who tried to...\n",
              "2  3.90255841338601E+017  ...  rt  call me sexist  but when i go to an auto p...\n",
              "3  5.68208850655916E+017  ...   wrong  isis follows the example of mohammed a...\n",
              "4  5.75596338802373E+017  ...                              mkr no no no no no no\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMZdFxVPybk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd833ea-903b-4047-ed13-fef47b5a5337"
      },
      "source": [
        "X = twitter_data['cleaned_tweets']\n",
        "y = np.array(twitter_data['oh_label'])\n",
        "\n",
        "sum(y)/len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23660862446622563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajtaQUui8ptG"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(twitter_data['cleaned_tweets'], twitter_data['oh_label'], test_size = 0.2, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1trFHsO8tIk"
      },
      "source": [
        "Run for subset of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eWzUON58ro6"
      },
      "source": [
        "twitter_subset = twitter_data.sample(10000)\n",
        "x_subset = twitter_subset['cleaned_tweets']\n",
        "y_subset = twitter_subset['oh_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_subset, y_subset, test_size = 0.2, random_state=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTgWniUC-qcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05f5f30-3a46-4773-ac27-e262368f9bdb"
      },
      "source": [
        "baseline = 1 - np.mean(y_train)\n",
        "baseline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7541249999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG21m7mB_TM5"
      },
      "source": [
        "The dataset is imbalanced, we are going to under-sample the data for balanced training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9BlLpKApCq"
      },
      "source": [
        "good = twitter_data[twitter_data['oh_label'] == 0]\n",
        "racist_sexist = twitter_data[twitter_data['oh_label'] == 1]\n",
        "\n",
        "good_undersample = good.sample(int(sum(y)))\n",
        "balanced_data = pd.concat([good_undersample, racist_sexist], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX39PGO1Kjk9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH2SekAvCvhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7c53cb-9571-4c7f-e6d2-bd967faaba41"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(balanced_data['cleaned_tweets'], balanced_data['oh_label'], test_size = 0.2, random_state=1)\n",
        "\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4711     as expected  when the terrorist group hamas wo...\n",
              "10126                                                here \n",
              "4797      in all seriousness  ive been dying my hair si...\n",
              "13621    rt   just so iâ€™m clear you have dogs named leo...\n",
              "8004       kat you are the biggest mole   i hope you ch...\n",
              "                               ...                        \n",
              "805                       kat is the daughter of satan mkr\n",
              "8717      wrong  apostacy is the equivalent of leaving ...\n",
              "10392     its obvious why the former president of the n...\n",
              "4754      can you explain the wage gap   what does the ...\n",
              "8440                kat and andre are the fuckin devil mkr\n",
              "Name: cleaned_tweets, Length: 17110, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtAu-PdCPybk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cc756d-1caa-4b6b-9c6e-0e677fa417a1"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 26.5MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=582735c69a78d182031467114375ccd8c05c06c8ee2bb676d5382e26fcf57ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By6eDGOoPybl"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7Mg3zfrfPybl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "cd8199da5da04fae81bab3a544c21c58",
            "8c81c81f79b0474185694de3da579878",
            "1561a13f9f19455c84034ed9d5bf1d51",
            "a67ad09ab62b4a548eb7f3d2944c266f",
            "3e8fe17f0f954224b8cbbc5e925138e7",
            "21ba8e47d7bb4ba38a569ca1ac6d4393",
            "d68d4e68a4444bf4a299db2bb804c0c7",
            "51ea411211e04a75a4b9533af865e3df",
            "c201b554a884417da6ff13ea2ad871f5",
            "2f37c03030c1458ebeb42ef12b7e1922",
            "c79b6d7b109046a09fcbe005d1a14788",
            "6f442eb07a8b4a48809075ae72670e8f",
            "4f24c9ab1b3f46588fd4b89d48874f9a",
            "12aa1f4f5c4841f0964852593d4c4ea5",
            "f10a00a35c2743a299a766b077460d61",
            "c354fdf6a73945e5bcf3d132c3977873"
          ]
        },
        "outputId": "1a7fd54f-f4c2-46be-ee81-1e754eb1c29a"
      },
      "source": [
        "bert_layer = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd8199da5da04fae81bab3a544c21c58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c201b554a884417da6ff13ea2ad871f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qZ8F-l48_Yo"
      },
      "source": [
        "Freezing layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it7Un3Yq8-vG"
      },
      "source": [
        "retrain_layers = []\n",
        "\n",
        "for retrain_layer_number in range(4):\n",
        "\n",
        "    layer_code = '_' + str(11 - retrain_layer_number)\n",
        "    retrain_layers.append(layer_code)\n",
        "\n",
        "for w in bert_layer.weights:\n",
        "    if not any([x in w.name for x in retrain_layers]):\n",
        "        w._trainable = False"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiqSeieP98QK"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alib0F9oFi4A"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "bert_inputs = tokenizer(list(X_train), padding=True, return_tensors='tf')\n",
        "dim = bert_inputs['input_ids'].shape[1]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZsbNjEMPybl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fb4fdc-ef68-446f-a5d5-c96b706e458a"
      },
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(dim), dtype='int32', name='input_ids')\n",
        "masks = tf.keras.layers.Input(shape=(dim), dtype='int32', name='mask')\n",
        "token_type_ids = tf.keras.layers.Input(shape=(dim), dtype='int32', name='token_types')\n",
        "\n",
        "bert_output = bert_layer([input_ids, masks, token_type_ids])\n",
        "\n",
        "\n",
        "cls = bert_output[1]\n",
        "\n",
        "hidden = tf.keras.layers.Dense(200, activation='relu')(cls)\n",
        "\n",
        "classification = tf.keras.layers.Dense(1, activation='sigmoid')(hidden)\n",
        "\n",
        "model = tf.keras.Model(inputs = [input_ids, masks, token_type_ids], outputs = classification)\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False),\n",
        "              # optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics='acc')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBjYe7WJPybm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a7e43c-60fb-47d9-bad7-1e1f352265e6"
      },
      "source": [
        "model.fit(x = [np.array(bert_inputs['input_ids']), np.array(bert_inputs['attention_mask']), np.array(bert_inputs['token_type_ids'])],\n",
        "          y = y_train,\n",
        "          epochs = 5,\n",
        "          validation_split = 0.2,\n",
        "          batch_size = 64)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5034 - acc: 0.7811WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "100/100 [==============================] - 48s 430ms/step - loss: 0.5027 - acc: 0.7814 - val_loss: 0.3420 - val_acc: 0.8587\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 41s 415ms/step - loss: 0.3691 - acc: 0.8359 - val_loss: 0.3310 - val_acc: 0.8656\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 41s 415ms/step - loss: 0.3137 - acc: 0.8706 - val_loss: 0.3118 - val_acc: 0.8706\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 42s 416ms/step - loss: 0.2834 - acc: 0.8854 - val_loss: 0.3041 - val_acc: 0.8838\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 42s 416ms/step - loss: 0.2278 - acc: 0.9103 - val_loss: 0.3006 - val_acc: 0.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9118ca1e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx0e3q2FPybm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0a9b5d-7365-4b0d-e71f-5d74ae4823f5"
      },
      "source": [
        "bert_test_inputs = tokenizer(list(X_test), padding='max_length', truncation=True, max_length = dim, return_tensors='tf')\n",
        "bert_test_inputs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2000, 44), dtype=int32, numpy=\n",
              "array([[  101,  2027,  2439, ...,     0,     0,     0],\n",
              "       [  101,  2327, 17710, ...,     0,     0,     0],\n",
              "       [  101,  2236, 12455, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101, 19387,  2023, ...,     0,     0,     0],\n",
              "       [  101,  2057,  2342, ...,     0,     0,     0],\n",
              "       [  101,  3342, 23332, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2000, 44), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2000, 44), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJlL1aGXYdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246dee50-bbe2-4500-8168-4768ea4e7949"
      },
      "source": [
        "y_pred = model.predict([np.array(bert_test_inputs['input_ids']), np.array(bert_test_inputs['attention_mask']), np.array(bert_test_inputs['token_type_ids'])])\n",
        "y_pred = np.array([1 if x[0] >= 0.5 else 0  for x in y_pred])\n",
        "\n",
        "print(\"accuracy: \" + str(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmHWUAOKYBRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab15ecdb-4fe9-4bc1-d20b-9c0172fac746"
      },
      "source": [
        "errors = pd.DataFrame((y_pred == y_test))\n",
        "error_index = np.array(errors[errors['oh_label'] == False].index)\n",
        "\n",
        "for error in error_index[:15]:\n",
        "  print(twitter_data.iloc[error]['Text'], twitter_data.iloc[error]['oh_label'])\n",
        "  print()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".@eaballesty @dileted @tim_geelen Those women are not exploited.  They make a calculated choice to use sex to advance careers. 1.0\n",
            "\n",
            "@IamStan is bitlocker any good? i've never used it. didn't realize i could gpg an entire drive, either. :) 0.0\n",
            "\n",
            "@AMohedin My 2:282 says that you can replace the testimony of one man with that of two women. 1.0\n",
            "\n",
            "@dankmtl 1400 years ago my ass. That was the beginning and it has never stopped. It is an ingrained part of Islam. 1.0\n",
            "\n",
            "Colin was pretty nice to the girls. Do you think he's giving them the dick? #MKR 1.0\n",
            "\n",
            "@mykitchenrules time! THE TEXAN IS BACK BABY! #mykitchenrules #mkr 0.0\n",
            "\n",
            "@KaylinEvergreen Twitter_ebooks on github 0.0\n",
            "\n",
            "RT @travisnashh: @YesYoureSexist because you hate a group doesn't make you sexist dumbass 1.0\n",
            "\n",
            "@LifeInKhilafah That just means that the only kinds of Europeans you will get are crazy. Other places have the brainwashed and uneducated. 0.0\n",
            "\n",
            "@Jizyacollector @AbuMusabAlTurki @islamofascist_ @_ProtocolShami True about RT.  However, there are Islamic organizations in US that could. 0.0\n",
            "\n",
            "RT @Itsjust55496420: I wasn't going to boycot MKR but the fact the Manu, Pete, the directors &amp; producers have chosen to ignore blatant straâ€¦ 0.0\n",
            "\n",
            "@Clashoftherats I also know that you are lying because I have three translated Qurans that say the same thing as the translations I gave you 1.0\n",
            "\n",
            "add a filter to toggle showing phone-verified accts in clients (requires devpolicy update, natch). 0.0\n",
            "\n",
            "@0xabad1dea these are museum pieces - if you can find authentic ones (it's rare), L fits up to like a size 22. 0.0\n",
            "\n",
            "@CavusSeyit @iAmCaticorn People who hate the Nazis are not extremists. And there is no diff between Islam and Nazis. 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opeVoY5COfzV",
        "outputId": "6079e9e9-1072-40c3-f269-30b11273f595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "twitter_data.iloc[error_index[0]]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                                         5.60847759482556E+017\n",
              "id                                            5.60847759482556E+017\n",
              "Text              .@eaballesty @dileted @tim_geelen Those women ...\n",
              "Annotation                                                   sexism\n",
              "oh_label                                                          1\n",
              "cleaned_tweets        those women are not exploited   they make ...\n",
              "Name: 11143, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkK-ciekaR-G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ARXHwZoHT9"
      },
      "source": [
        "Strong possibility that BERT is just calling for one class? Why is that? There is a 25% imbalance in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2KVHI55ojwA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}