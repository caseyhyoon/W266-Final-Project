{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyberbullying Auto Detection\n",
    "*Wenqu Wang, Casey Yoon*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy, TensorFlow, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_sentiment.ipynb',\n",
       " 'twitter_racism_parsed_dataset.csv',\n",
       " '.git',\n",
       " 'twitter_parsed_dataset.csv',\n",
       " 'Untitled.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'twitter_sexism_parsed_dataset.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index                     id  \\\n",
       "0  5.74948705591165E+017  5.74948705591165E+017   \n",
       "1  5.71917888690393E+017  5.71917888690393E+017   \n",
       "2  3.90255841338601E+017  3.90255841338601E+017   \n",
       "3  5.68208850655916E+017  5.68208850655916E+017   \n",
       "4  5.75596338802373E+017  5.75596338802373E+017   \n",
       "\n",
       "                                                Text Annotation  oh_label  \n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0  \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       none       0.0  \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0  \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0  \n",
       "4                             #mkr No No No No No No       none       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We aggregate all the data into one dataframe\n",
    "\n",
    "parsed = pd.read_csv('twitter_parsed_dataset.csv')\n",
    "racism = pd.read_csv('twitter_racism_parsed_dataset.csv')\n",
    "sexism = pd.read_csv('twitter_sexism_parsed_dataset.csv')\n",
    "\n",
    "twitter_data = pd.concat([parsed, racism, sexism]).dropna()\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9327     There is such a diff between reality &amp; wha...\n",
       "14633    Katie's a fatty!! Model!!!! Hahahaha #MKR #kil...\n",
       "4197     @Nibelsnarfabarf @srhbutts @GRIMACHU it is rea...\n",
       "3534     @MaxOfS2D @StephenAtWar Origin is a flaming pi...\n",
       "4500     No, you don't. @Shut_Up_Jeff: I thought of a r...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(twitter_data['Text'], twitter_data['oh_label'], test_size=0.20, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9327     0.0\n",
       "14633    1.0\n",
       "4197     0.0\n",
       "3534     0.0\n",
       "4500     1.0\n",
       "Name: oh_label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=500)\n",
    "X_vectrain = vec.fit_transform(X_train).toarray()\n",
    "X_vectest = vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609513274336284"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Baseline accuracy, predicting all of one class.\n",
    "1 - np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.8433159753737457\n",
      "accuracy =  0.8535398230088496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack_wenquwang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "clf = LogisticRegression(random_state=0).fit(X_vectrain, y_train)\n",
    "pred = clf.predict(X_vectest)\n",
    "print(\"f1_score = \", metrics.f1_score(y_test, pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 64)                32064     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 36,289\n",
      "Trainable params: 36,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,input_shape=(500,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.3971 - acc: 0.8325\n",
      "Epoch 2/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.3204 - acc: 0.8723\n",
      "Epoch 3/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.2695 - acc: 0.8995\n",
      "Epoch 4/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.2232 - acc: 0.9205\n",
      "Epoch 5/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.1806 - acc: 0.9375\n",
      "Epoch 6/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.1548 - acc: 0.9467\n",
      "Epoch 7/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.1326 - acc: 0.9541\n",
      "Epoch 8/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.1176 - acc: 0.9595\n",
      "Epoch 9/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.1066 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1130/1130 [==============================] - 1s 1ms/step - loss: 0.0971 - acc: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7d92b0b50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_vectrain,y_train,batch_size=32,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_vectest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.9468722025892737\n",
      "accuracy =  0.9484513274336284\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score = \", metrics.f1_score(y_test, pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 5)            2500      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 128)          3328      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 7,129\n",
      "Trainable params: 7,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_dim = 5\n",
    "model.add(layers.Embedding(500, embedding_dim, input_length=500))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5502 - accuracy: 0.7636\n",
      "Epoch 2/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5450 - accuracy: 0.7640\n",
      "Epoch 3/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5448 - accuracy: 0.7640\n",
      "Epoch 4/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5451 - accuracy: 0.7640\n",
      "Epoch 5/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5448 - accuracy: 0.7640\n",
      "Epoch 6/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5447 - accuracy: 0.7640\n",
      "Epoch 7/10\n",
      "1130/1130 [==============================] - 35s 31ms/step - loss: 0.5448 - accuracy: 0.7640\n",
      "Epoch 8/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5449 - accuracy: 0.7640\n",
      "Epoch 9/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5447 - accuracy: 0.7640\n",
      "Epoch 10/10\n",
      "1130/1130 [==============================] - 34s 30ms/step - loss: 0.5448 - accuracy: 0.7640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7ca889df0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_vectrain,y_train,batch_size=32,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.6576523878906878\n",
      "accuracy =  0.7609513274336284\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(X_vectest)\n",
    "print(\"f1_score = \", metrics.f1_score(y_test, pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
