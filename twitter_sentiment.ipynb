{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy, TensorFlow, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_parsed_dataset.csv',\n",
       " 'twitter_sentiment.ipynb',\n",
       " 'twitter_racism_parsed_dataset.csv',\n",
       " 'twitter_sexism_parsed_dataset.csv',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index                     id  \\\n",
       "0  5.74948705591165E+017  5.74948705591165E+017   \n",
       "1  5.71917888690393E+017  5.71917888690393E+017   \n",
       "2  3.90255841338601E+017  3.90255841338601E+017   \n",
       "3  5.68208850655916E+017  5.68208850655916E+017   \n",
       "4  5.75596338802373E+017  5.75596338802373E+017   \n",
       "\n",
       "                                                Text Annotation  oh_label  \n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0  \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       none       0.0  \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0  \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0  \n",
       "4                             #mkr No No No No No No       none       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We aggregate all the data into one dataframe\n",
    "\n",
    "parsed = pd.read_csv('twitter_parsed_dataset.csv')\n",
    "racism = pd.read_csv('twitter_racism_parsed_dataset.csv')\n",
    "sexism = pd.read_csv('twitter_sexism_parsed_dataset.csv')\n",
    "\n",
    "twitter_data = pd.concat([parsed, racism, sexism]).dropna()\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9327     There is such a diff between reality &amp; wha...\n",
       "14633    Katie's a fatty!! Model!!!! Hahahaha #MKR #kil...\n",
       "4197     @Nibelsnarfabarf @srhbutts @GRIMACHU it is rea...\n",
       "3534     @MaxOfS2D @StephenAtWar Origin is a flaming pi...\n",
       "4500     No, you don't. @Shut_Up_Jeff: I thought of a r...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(twitter_data['Text'], twitter_data['oh_label'], test_size=0.20, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36157 9040\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9327     0.0\n",
       "14633    1.0\n",
       "4197     0.0\n",
       "3534     0.0\n",
       "4500     1.0\n",
       "Name: oh_label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "\n",
    "X_vectrain = vec.fit_transform(X_train)\n",
    "X_vectest = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609513274336284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Baseline accuracy, predicting all of one class.\n",
    "\n",
    "1 - np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.8811389720311346\n",
      "accuracy =  0.8888274336283186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_vectrain, y_train)\n",
    "pred = clf.predict(X_vectest)\n",
    "print(\"f1_score = \", metrics.f1_score(y_test, pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jupyter/anaconda3/lib/python3.8/site-packages (21.0.1)\n",
      "Requirement already satisfied: nltk in /home/jupyter/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: click in /home/jupyter/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /home/jupyter/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in /home/jupyter/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in /home/jupyter/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: gensim in /home/jupyter/anaconda3/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/jupyter/anaconda3/lib/python3.8/site-packages (from gensim) (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/jupyter/anaconda3/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/jupyter/anaconda3/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/jupyter/anaconda3/lib/python3.8/site-packages (from gensim) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @halalflaws @biebervalue @greenlinerzjm I read...\n",
       "1        @ShreyaBafna3 Now you idiots claim that people...\n",
       "2        RT @Mooseoftorment Call me sexist, but when I ...\n",
       "3        @g0ssipsquirrelx Wrong, ISIS follows the examp...\n",
       "4                                   #mkr No No No No No No\n",
       "                               ...                        \n",
       "14876    @RaikonL @finaleve @mja333 WHY DO YOU HATE FRE...\n",
       "14877    It is unconscionable that our regulatory bodie...\n",
       "14878    @Dartanveerahmad @Janx53 @geehall1 We want ISI...\n",
       "14879    #mkr  Unbelievable how low Kat &amp; Andre wil...\n",
       "14880    RT @JamesMakienko: @omeisy @yemenrightsmon Peo...\n",
       "Name: Text, Length: 45197, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, read, them, in, context, no, change, in, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[now, you, idiots, claim, that, people, who, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[rt, call, me, sexist, but, when, i, go, to, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[wrong, isis, follows, the, example, of, moham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[#mkr, no, no, no, no, no, no]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index                     id  \\\n",
       "0  5.74948705591165E+017  5.74948705591165E+017   \n",
       "1  5.71917888690393E+017  5.71917888690393E+017   \n",
       "2  3.90255841338601E+017  3.90255841338601E+017   \n",
       "3  5.68208850655916E+017  5.68208850655916E+017   \n",
       "4  5.75596338802373E+017  5.75596338802373E+017   \n",
       "\n",
       "                                                Text Annotation  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       none       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0   \n",
       "4                             #mkr No No No No No No       none       0.0   \n",
       "\n",
       "                                    tokenized_tweets  \n",
       "0  [i, read, them, in, context, no, change, in, m...  \n",
       "1  [now, you, idiots, claim, that, people, who, t...  \n",
       "2  [rt, call, me, sexist, but, when, i, go, to, a...  \n",
       "3  [wrong, isis, follows, the, example, of, moham...  \n",
       "4                     [#mkr, no, no, no, no, no, no]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning tweets\n",
    "\n",
    "import re\n",
    "\n",
    "def cleaning_tweets(tweet):\n",
    "    # 1. Remove Twitter handles (@user)\n",
    "    users = re.findall(\"@[\\w]*\", tweet) # tokenizing\n",
    "    for user in users:\n",
    "        tweet = re.sub(user, '', tweet)\n",
    "\n",
    "    # 2. Remove, Punctuations, Numbers, and Special Characters (keep hashtags)\n",
    "    tweet = re.sub(\"[^a-zA-Z#]\", \" \", tweet)\n",
    "\n",
    "    # 3. Lowercase all\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # 4. Splitting text into tokens\n",
    "    tweet = tweet.split()\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "twitter_data['tokenized_tweets'] = twitter_data['Text'].apply(cleaning_tweets)\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woo', 'can', 't', 'wait', 'to', 'see', 'what', 'happens', '#mkr']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data['tokenized_tweets'].iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, read, them, in, context, no, change, in, m...</td>\n",
       "      <td>i read them in context no change in meaning th...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[now, you, idiots, claim, that, people, who, t...</td>\n",
       "      <td>now you idiots claim that people who tried to ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[rt, call, me, sexist, but, when, i, go, to, a...</td>\n",
       "      <td>rt call me sexist but when i go to an auto pla...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[wrong, isis, follows, the, example, of, moham...</td>\n",
       "      <td>wrong isis follows the example of mohammed and...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[#mkr, no, no, no, no, no, no]</td>\n",
       "      <td>#mkr no no no no no no</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index                     id  \\\n",
       "0  5.74948705591165E+017  5.74948705591165E+017   \n",
       "1  5.71917888690393E+017  5.71917888690393E+017   \n",
       "2  3.90255841338601E+017  3.90255841338601E+017   \n",
       "3  5.68208850655916E+017  5.68208850655916E+017   \n",
       "4  5.75596338802373E+017  5.75596338802373E+017   \n",
       "\n",
       "                                                Text Annotation  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       none       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0   \n",
       "4                             #mkr No No No No No No       none       0.0   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [i, read, them, in, context, no, change, in, m...   \n",
       "1  [now, you, idiots, claim, that, people, who, t...   \n",
       "2  [rt, call, me, sexist, but, when, i, go, to, a...   \n",
       "3  [wrong, isis, follows, the, example, of, moham...   \n",
       "4                     [#mkr, no, no, no, no, no, no]   \n",
       "\n",
       "                                      cleaned_tweets  num_tokens  \n",
       "0  i read them in context no change in meaning th...          18  \n",
       "1  now you idiots claim that people who tried to ...          22  \n",
       "2  rt call me sexist but when i go to an auto pla...          19  \n",
       "3  wrong isis follows the example of mohammed and...          11  \n",
       "4                             #mkr no no no no no no           7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data['cleaned_tweets'] = twitter_data['tokenized_tweets'].apply(lambda x: ' '.join(x))\n",
    "twitter_data['num_tokens'] = twitter_data['tokenized_tweets'].apply(len)\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f55146bf940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(twitter_data['tokenized_tweets'],\n",
    "               size = 200,\n",
    "               window = 5,\n",
    "               min_count = 2,\n",
    "               sg = 1,\n",
    "               hs = 0,\n",
    "               negative = 10,\n",
    "               workers = 32,\n",
    "               seed = 1)\n",
    "\n",
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-10e809eb9fbe>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  w2v.most_similar(positive='sexist')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('swear', 0.7739920020103455),\n",
       " ('misandrist', 0.7709363698959351),\n",
       " ('females', 0.7590835690498352),\n",
       " ('im', 0.7566421031951904),\n",
       " ('basketball', 0.734123706817627),\n",
       " ('rappers', 0.7287617921829224),\n",
       " ('comedians', 0.7186075448989868),\n",
       " ('analysts', 0.7161632180213928),\n",
       " ('#sexist', 0.7120012044906616),\n",
       " ('announcers', 0.7095776796340942)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive='sexist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-3ed436464d62>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  w2v.most_similar(positive='racist')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('device', 0.7912424802780151),\n",
       " ('bigot', 0.7736752033233643),\n",
       " ('fashioned', 0.7657896280288696),\n",
       " ('rhetorical', 0.7646394371986389),\n",
       " ('unpopular', 0.7619739174842834),\n",
       " ('biggot', 0.7582675218582153),\n",
       " ('retarded', 0.7559173107147217),\n",
       " ('bigoted', 0.7542294859886169),\n",
       " ('wnba', 0.7538695931434631),\n",
       " ('monger', 0.7505632042884827)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive='racist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, read, them, in, context, no, change, in, m...</td>\n",
       "      <td>i read them in context no change in meaning th...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[now, you, idiots, claim, that, people, who, t...</td>\n",
       "      <td>now you idiots claim that people who tried to ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[rt, call, me, sexist, but, when, i, go, to, a...</td>\n",
       "      <td>rt call me sexist but when i go to an auto pla...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[wrong, isis, follows, the, example, of, moham...</td>\n",
       "      <td>wrong isis follows the example of mohammed and...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[#mkr, no, no, no, no, no, no]</td>\n",
       "      <td>#mkr no no no no no no</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index                     id  \\\n",
       "0  5.74948705591165E+017  5.74948705591165E+017   \n",
       "1  5.71917888690393E+017  5.71917888690393E+017   \n",
       "2  3.90255841338601E+017  3.90255841338601E+017   \n",
       "3  5.68208850655916E+017  5.68208850655916E+017   \n",
       "4  5.75596338802373E+017  5.75596338802373E+017   \n",
       "\n",
       "                                                Text Annotation  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       none       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0   \n",
       "4                             #mkr No No No No No No       none       0.0   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [i, read, them, in, context, no, change, in, m...   \n",
       "1  [now, you, idiots, claim, that, people, who, t...   \n",
       "2  [rt, call, me, sexist, but, when, i, go, to, a...   \n",
       "3  [wrong, isis, follows, the, example, of, moham...   \n",
       "4                     [#mkr, no, no, no, no, no, no]   \n",
       "\n",
       "                                      cleaned_tweets  num_tokens  \n",
       "0  i read them in context no change in meaning th...          18  \n",
       "1  now you idiots claim that people who tried to ...          22  \n",
       "2  rt call me sexist but when i go to an auto pla...          19  \n",
       "3  wrong isis follows the example of mohammed and...          11  \n",
       "4                             #mkr no no no no no no           7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Consider tweets that don't produce any tokens, delete those\n",
    "twitter_data = twitter_data[twitter_data['num_tokens'] > 0 ]\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-0559590e5a63>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  w2v[twitter_data['tokenized_tweets'].iloc[0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.08616858,  0.6018554 , -0.0041653 , ...,  0.02202413,\n",
       "         0.10708536, -0.2065192 ],\n",
       "       [ 0.08572198,  0.270992  ,  0.08413573, ..., -0.00950772,\n",
       "         0.05047496, -0.44735977],\n",
       "       [-0.11475495,  0.6492598 , -0.15602793, ...,  0.2821606 ,\n",
       "        -0.41180852, -0.042546  ],\n",
       "       ...,\n",
       "       [-0.19178945,  0.8881018 , -0.23951456, ..., -0.18243316,\n",
       "        -0.40385884, -0.81736225],\n",
       "       [-0.36884183,  1.0916493 , -0.31159085, ..., -0.45013034,\n",
       "        -0.5191194 , -0.75563383],\n",
       "       [-0.16900884,  0.57097   , -0.29769507, ..., -0.01783078,\n",
       "        -0.00949285, -0.24126376]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v[twitter_data['tokenized_tweets'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-205c5faf99a4>:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec += w2v[word].reshape((1, size))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077116</td>\n",
       "      <td>0.529059</td>\n",
       "      <td>-0.032810</td>\n",
       "      <td>0.273359</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>-0.003853</td>\n",
       "      <td>0.238130</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054935</td>\n",
       "      <td>0.130297</td>\n",
       "      <td>-0.121414</td>\n",
       "      <td>-0.029483</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>-0.022517</td>\n",
       "      <td>-0.156276</td>\n",
       "      <td>-0.139557</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>-0.221789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.069066</td>\n",
       "      <td>0.358940</td>\n",
       "      <td>0.117288</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>-0.165394</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>-0.010704</td>\n",
       "      <td>0.127601</td>\n",
       "      <td>-0.050857</td>\n",
       "      <td>0.053011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178487</td>\n",
       "      <td>0.208656</td>\n",
       "      <td>-0.174308</td>\n",
       "      <td>0.067932</td>\n",
       "      <td>-0.133147</td>\n",
       "      <td>-0.077760</td>\n",
       "      <td>-0.096673</td>\n",
       "      <td>-0.029129</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.004285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.086911</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>0.141301</td>\n",
       "      <td>-0.121793</td>\n",
       "      <td>0.245582</td>\n",
       "      <td>-0.090362</td>\n",
       "      <td>0.096808</td>\n",
       "      <td>0.124401</td>\n",
       "      <td>0.156268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052106</td>\n",
       "      <td>0.170952</td>\n",
       "      <td>-0.246308</td>\n",
       "      <td>0.074399</td>\n",
       "      <td>-0.147604</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>-0.019963</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.101775</td>\n",
       "      <td>-0.117584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.441088</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>0.286847</td>\n",
       "      <td>-0.271401</td>\n",
       "      <td>0.176073</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.229128</td>\n",
       "      <td>-0.110752</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130451</td>\n",
       "      <td>0.245162</td>\n",
       "      <td>-0.096759</td>\n",
       "      <td>-0.019220</td>\n",
       "      <td>-0.007197</td>\n",
       "      <td>-0.150246</td>\n",
       "      <td>-0.185466</td>\n",
       "      <td>-0.078087</td>\n",
       "      <td>0.135357</td>\n",
       "      <td>0.038776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>-0.203437</td>\n",
       "      <td>0.182091</td>\n",
       "      <td>0.756588</td>\n",
       "      <td>0.411304</td>\n",
       "      <td>0.454717</td>\n",
       "      <td>-0.177291</td>\n",
       "      <td>0.114346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318886</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>-0.100999</td>\n",
       "      <td>0.357696</td>\n",
       "      <td>-0.243786</td>\n",
       "      <td>-0.019430</td>\n",
       "      <td>-0.313556</td>\n",
       "      <td>-0.055227</td>\n",
       "      <td>0.111527</td>\n",
       "      <td>-0.253051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45133</th>\n",
       "      <td>-0.176219</td>\n",
       "      <td>0.523891</td>\n",
       "      <td>-0.085382</td>\n",
       "      <td>-0.035549</td>\n",
       "      <td>-0.076849</td>\n",
       "      <td>0.464065</td>\n",
       "      <td>-0.177175</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>-0.112153</td>\n",
       "      <td>0.104145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>0.299437</td>\n",
       "      <td>-0.240835</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.067988</td>\n",
       "      <td>-0.137045</td>\n",
       "      <td>-0.149745</td>\n",
       "      <td>0.178143</td>\n",
       "      <td>0.190889</td>\n",
       "      <td>-0.060944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45134</th>\n",
       "      <td>0.030734</td>\n",
       "      <td>0.407065</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.055956</td>\n",
       "      <td>-0.191023</td>\n",
       "      <td>0.207260</td>\n",
       "      <td>-0.091704</td>\n",
       "      <td>0.081062</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>0.052431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027022</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>-0.128721</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>-0.036755</td>\n",
       "      <td>-0.064434</td>\n",
       "      <td>-0.065790</td>\n",
       "      <td>-0.029154</td>\n",
       "      <td>0.131945</td>\n",
       "      <td>-0.089151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45135</th>\n",
       "      <td>-0.157921</td>\n",
       "      <td>0.416517</td>\n",
       "      <td>-0.034118</td>\n",
       "      <td>0.076544</td>\n",
       "      <td>-0.160337</td>\n",
       "      <td>0.219227</td>\n",
       "      <td>-0.062522</td>\n",
       "      <td>0.109040</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.113055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005307</td>\n",
       "      <td>0.202154</td>\n",
       "      <td>-0.080051</td>\n",
       "      <td>0.059469</td>\n",
       "      <td>-0.066018</td>\n",
       "      <td>-0.100507</td>\n",
       "      <td>-0.137580</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.122055</td>\n",
       "      <td>-0.033227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45136</th>\n",
       "      <td>-0.054480</td>\n",
       "      <td>0.432186</td>\n",
       "      <td>-0.050923</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>-0.117701</td>\n",
       "      <td>0.233391</td>\n",
       "      <td>-0.011567</td>\n",
       "      <td>-0.080663</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.036834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>-0.147487</td>\n",
       "      <td>0.124441</td>\n",
       "      <td>-0.215757</td>\n",
       "      <td>-0.120879</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>-0.063305</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>-0.192290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45137</th>\n",
       "      <td>-0.024702</td>\n",
       "      <td>0.395719</td>\n",
       "      <td>-0.068625</td>\n",
       "      <td>0.194602</td>\n",
       "      <td>-0.091482</td>\n",
       "      <td>0.156654</td>\n",
       "      <td>-0.083913</td>\n",
       "      <td>0.169724</td>\n",
       "      <td>0.050032</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043429</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>-0.135834</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.066123</td>\n",
       "      <td>-0.071553</td>\n",
       "      <td>-0.066432</td>\n",
       "      <td>-0.073927</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>-0.068393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45138 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.077116  0.529059 -0.032810  0.273359  0.017446  0.228200 -0.003853   \n",
       "1     -0.069066  0.358940  0.117288  0.029919 -0.165394  0.119998 -0.010704   \n",
       "2     -0.086911  0.418334  0.102821  0.141301 -0.121793  0.245582 -0.090362   \n",
       "3      0.033125  0.441088  0.051957  0.286847 -0.271401  0.176073  0.021853   \n",
       "4      0.110687  0.646871  0.001008 -0.203437  0.182091  0.756588  0.411304   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "45133 -0.176219  0.523891 -0.085382 -0.035549 -0.076849  0.464065 -0.177175   \n",
       "45134  0.030734  0.407065  0.021193  0.055956 -0.191023  0.207260 -0.091704   \n",
       "45135 -0.157921  0.416517 -0.034118  0.076544 -0.160337  0.219227 -0.062522   \n",
       "45136 -0.054480  0.432186 -0.050923  0.016114 -0.117701  0.233391 -0.011567   \n",
       "45137 -0.024702  0.395719 -0.068625  0.194602 -0.091482  0.156654 -0.083913   \n",
       "\n",
       "            7         8         9    ...       190       191       192  \\\n",
       "0      0.238130  0.010053  0.231009  ... -0.054935  0.130297 -0.121414   \n",
       "1      0.127601 -0.050857  0.053011  ... -0.178487  0.208656 -0.174308   \n",
       "2      0.096808  0.124401  0.156268  ... -0.052106  0.170952 -0.246308   \n",
       "3      0.229128 -0.110752  0.010660  ... -0.130451  0.245162 -0.096759   \n",
       "4      0.454717 -0.177291  0.114346  ...  0.318886  0.521368 -0.100999   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "45133  0.231347 -0.112153  0.104145  ...  0.027699  0.299437 -0.240835   \n",
       "45134  0.081062 -0.022519  0.052431  ... -0.027022  0.209386 -0.128721   \n",
       "45135  0.109040  0.011671  0.113055  ... -0.005307  0.202154 -0.080051   \n",
       "45136 -0.080663  0.135087  0.036834  ...  0.059621  0.297346 -0.147487   \n",
       "45137  0.169724  0.050032  0.048614  ... -0.043429  0.195492 -0.135834   \n",
       "\n",
       "            193       194       195       196       197       198       199  \n",
       "0     -0.029483  0.006110 -0.022517 -0.156276 -0.139557  0.008158 -0.221789  \n",
       "1      0.067932 -0.133147 -0.077760 -0.096673 -0.029129  0.038120  0.004285  \n",
       "2      0.074399 -0.147604  0.009140 -0.019963  0.086100  0.101775 -0.117584  \n",
       "3     -0.019220 -0.007197 -0.150246 -0.185466 -0.078087  0.135357  0.038776  \n",
       "4      0.357696 -0.243786 -0.019430 -0.313556 -0.055227  0.111527 -0.253051  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "45133  0.082156  0.067988 -0.137045 -0.149745  0.178143  0.190889 -0.060944  \n",
       "45134  0.135864 -0.036755 -0.064434 -0.065790 -0.029154  0.131945 -0.089151  \n",
       "45135  0.059469 -0.066018 -0.100507 -0.137580 -0.004005  0.122055 -0.033227  \n",
       "45136  0.124441 -0.215757 -0.120879 -0.002591 -0.063305  0.048833 -0.192290  \n",
       "45137  0.095700  0.066123 -0.071553 -0.066432 -0.073927  0.041374 -0.068393  \n",
       "\n",
       "[45138 rows x 200 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += w2v[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "wordvec_arrays = np.zeros((len(twitter_data['tokenized_tweets']), 200))\n",
    "\n",
    "for i in range(len(twitter_data['tokenized_tweets'])):\n",
    "    wordvec_arrays[i, :] = word_vector(twitter_data['tokenized_tweets'].iloc[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_X_train, w2v_X_test, w2v_y_train, w2v_y_test = train_test_split(wordvec_df, twitter_data['oh_label'], test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.8076017391535372\n",
      "accuracy =  0.8243243243243243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "### Word2vec w/ Logistic Regression\n",
    "\n",
    "clf_w2v = LogisticRegression(random_state=0).fit(w2v_X_train, w2v_y_train)\n",
    "pred = clf_w2v.predict(w2v_X_test)\n",
    "print(\"f1_score = \", metrics.f1_score(w2v_y_test, pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(w2v_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,089\n",
      "Trainable params: 17,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Word2vec w/ NN\n",
    "\n",
    "# Define Neural Network\n",
    "NN = Sequential()\n",
    "NN.add(Dense(64,input_shape=(200,)))\n",
    "NN.add(Dropout(0.2))\n",
    "NN.add(Activation('relu'))\n",
    "NN.add(Dense(64))\n",
    "NN.add(Dropout(0.2))\n",
    "NN.add(Activation('relu'))\n",
    "NN.add(Dense(1))\n",
    "NN.add(Activation('sigmoid'))\n",
    "NN.summary()\n",
    "NN.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.4361 - acc: 0.8100\n",
      "Epoch 2/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3965 - acc: 0.8304\n",
      "Epoch 3/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3838 - acc: 0.8361\n",
      "Epoch 4/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3756 - acc: 0.8416\n",
      "Epoch 5/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3674 - acc: 0.8460\n",
      "Epoch 6/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3611 - acc: 0.8498\n",
      "Epoch 7/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3573 - acc: 0.8499\n",
      "Epoch 8/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3522 - acc: 0.8530\n",
      "Epoch 9/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3465 - acc: 0.8564\n",
      "Epoch 10/10\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3434 - acc: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f55106591c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(w2v_X_train, w2v_y_train, batch_size=34, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-f71962f46e7a>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "NN_pred = NN.predict_classes(w2v_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score =  0.8450172316307162\n",
      "accuracy =  0.8481391227292867\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score = \", metrics.f1_score(w2v_y_test, NN_pred, average=\"weighted\"))\n",
    "print(\"accuracy = \", metrics.accuracy_score(w2v_y_test, NN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19645"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(w2v.wv.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2vec w/ CNN\n",
    "\n",
    "# CNN = Sequential()\n",
    "# embedding_dim = 5\n",
    "# CNN.add(layers.Input(shape=200,))\n",
    "# CNN.add(layers.Embedding(vocab_size, embedding_dim, input_length=200))\n",
    "# CNN.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "# CNN.add(layers.GlobalMaxPooling1D())\n",
    "# CNN.add(layers.Dense(10, activation='relu'))\n",
    "# CNN.add(layers.Dense(1, activation='sigmoid'))\n",
    "# CNN.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['acc'])\n",
    "# CNN.summary()\n",
    "\n",
    "wordids = layers.Input(shape=(200,))\n",
    "CNN = layers.Embedding(vocab_size,200 , 10, input_length=200)(wordids)\n",
    "CNN = layers.Conv1D(filters=2, kernel_size=2, activation='relu')(CNN)\n",
    "CNN = layers.GlobalMaxPooling1D()(CNN)\n",
    "CNN = layers.Dropout(rate=0.7)(CNN)\n",
    "CNN = layers.Dense(10, activation='relu')(CNN)\n",
    "CNN = layers.Dense(2, activation='relu')(CNN)\n",
    "CNN = layers.Dense(2, activation='relu')(CNN)\n",
    "prediction = layers.Dense(2, activation='softmax')(CNN)\n",
    "\n",
    "CNN_model = keras.Model(inputs=wordids, outputs=prediction)\n",
    "CNN_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f93f8b3e2b0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>0.066636</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>-0.076465</td>\n",
       "      <td>-0.166810</td>\n",
       "      <td>0.170999</td>\n",
       "      <td>0.043313</td>\n",
       "      <td>0.227367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343142</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.230042</td>\n",
       "      <td>0.190709</td>\n",
       "      <td>0.158190</td>\n",
       "      <td>0.210799</td>\n",
       "      <td>-0.107453</td>\n",
       "      <td>0.380495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>0.058817</td>\n",
       "      <td>-0.033192</td>\n",
       "      <td>0.148476</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.091150</td>\n",
       "      <td>-0.139191</td>\n",
       "      <td>-0.182401</td>\n",
       "      <td>0.186856</td>\n",
       "      <td>-0.156304</td>\n",
       "      <td>0.218057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>-0.047964</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.214617</td>\n",
       "      <td>0.227429</td>\n",
       "      <td>0.121006</td>\n",
       "      <td>0.339526</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>0.380185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>0.134369</td>\n",
       "      <td>-0.065956</td>\n",
       "      <td>0.039868</td>\n",
       "      <td>0.067017</td>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>-0.105362</td>\n",
       "      <td>0.171509</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.050634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333299</td>\n",
       "      <td>-0.063083</td>\n",
       "      <td>0.188317</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.343282</td>\n",
       "      <td>0.256595</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.427071</td>\n",
       "      <td>-0.098763</td>\n",
       "      <td>0.207447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23214</th>\n",
       "      <td>0.070986</td>\n",
       "      <td>0.048851</td>\n",
       "      <td>0.101083</td>\n",
       "      <td>0.066231</td>\n",
       "      <td>-0.098585</td>\n",
       "      <td>-0.140182</td>\n",
       "      <td>-0.089963</td>\n",
       "      <td>0.147331</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>0.250309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.202967</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>0.166367</td>\n",
       "      <td>0.162618</td>\n",
       "      <td>0.066444</td>\n",
       "      <td>0.179394</td>\n",
       "      <td>-0.262422</td>\n",
       "      <td>0.355086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269</th>\n",
       "      <td>0.099716</td>\n",
       "      <td>-0.066550</td>\n",
       "      <td>0.196736</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>-0.124994</td>\n",
       "      <td>-0.049255</td>\n",
       "      <td>-0.283008</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>-0.149655</td>\n",
       "      <td>0.192325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165654</td>\n",
       "      <td>0.212479</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.164197</td>\n",
       "      <td>0.179401</td>\n",
       "      <td>0.115111</td>\n",
       "      <td>0.391958</td>\n",
       "      <td>-0.112060</td>\n",
       "      <td>0.402351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "11832  0.066636 -0.055801  0.104545  0.055636 -0.036905 -0.076465 -0.166810   \n",
       "2053   0.058817 -0.033192  0.148476 -0.001522 -0.091150 -0.139191 -0.182401   \n",
       "12650  0.134369 -0.065956  0.039868  0.067017  0.038138  0.015747 -0.105362   \n",
       "23214  0.070986  0.048851  0.101083  0.066231 -0.098585 -0.140182 -0.089963   \n",
       "19269  0.099716 -0.066550  0.196736  0.141789 -0.124994 -0.049255 -0.283008   \n",
       "\n",
       "            7         8         9    ...       190       191       192  \\\n",
       "11832  0.170999  0.043313  0.227367  ...  0.343142  0.009389  0.058588   \n",
       "2053   0.186856 -0.156304  0.218057  ...  0.194500  0.085747 -0.047964   \n",
       "12650  0.171509  0.002566  0.050634  ...  0.333299 -0.063083  0.188317   \n",
       "23214  0.147331  0.020894  0.250309  ...  0.237544 -0.054575  0.202967   \n",
       "19269  0.175376 -0.149655  0.192325  ...  0.165654  0.212479  0.015772   \n",
       "\n",
       "            193       194       195       196       197       198       199  \n",
       "11832  0.007882  0.230042  0.190709  0.158190  0.210799 -0.107453  0.380495  \n",
       "2053   0.023323  0.214617  0.227429  0.121006  0.339526 -0.002729  0.380185  \n",
       "12650  0.017313  0.343282  0.256595  0.021563  0.427071 -0.098763  0.207447  \n",
       "23214 -0.067759  0.166367  0.162618  0.066444  0.179394 -0.262422  0.355086  \n",
       "19269  0.044800  0.164197  0.179401  0.115111  0.391958 -0.112060  0.402351  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 112/1129 [=>............................] - ETA: 8s - loss: 0.5834 - accuracy: 0.7631"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[9,63] = -1 is not in [0, 19645)\n\t [[node functional_40/embedding_32/embedding_lookup (defined at <ipython-input-148-3b2b0ee89568>:2) ]] [Op:__inference_train_function_50915]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_40/embedding_32/embedding_lookup:\n functional_40/embedding_32/embedding_lookup/50621 (defined at /home/jupyter/anaconda3/lib/python3.8/contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-3b2b0ee89568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[9,63] = -1 is not in [0, 19645)\n\t [[node functional_40/embedding_32/embedding_lookup (defined at <ipython-input-148-3b2b0ee89568>:2) ]] [Op:__inference_train_function_50915]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_40/embedding_32/embedding_lookup:\n functional_40/embedding_32/embedding_lookup/50621 (defined at /home/jupyter/anaconda3/lib/python3.8/contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "CNN_model.reset_states()\n",
    "CNN_model.fit(w2v_X_train, w2v_y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
